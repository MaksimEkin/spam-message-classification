{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Messages Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Classify Spam Messages. Compare Tfid with plain text results, Hash Vectorizer with n-Grams results where n=2, and Burrows Wheeler Transform Distance (BWTD) with plain text and n-gram results.<br>\n",
    "**Approach**:\n",
    "<ol>\n",
    "    <li>Supervised Learning task, because given labeled traning examples</li>\n",
    "    <li>Binary Classification task</li>\n",
    "    <li>Use plain text with Tfid</li>\n",
    "    <li>Use N-Grams with Hash Vectorizer</li>\n",
    "    <li>Use plain text with BWTD</li>\n",
    "    <li>Use N-Grams with BWTD</li>\n",
    "    <li>There is no continuous flow of data, no need to adjust to changing data, and the data is small enough to fit in memmory: Batch Learning</li>\n",
    "</ol>\n",
    "\n",
    "**Data:** [SMS Spam Collection Dataset | Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset)<br>\n",
    "**BWTD:** [Burrows Wheeler Transform Distance (BWTD) by Dr. Edward Raff](https://github.com/EdwardRaff/pyBWMD)<br><br>\n",
    "**Project Author:** Maksim Ekin Eren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyBWMD import vectorize\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print out classification model report\n",
    "def classification_report(model_name, test, pred, label):    \n",
    "    print(model_name, \":\\n\")\n",
    "    print(\"Accuracy Score: \", '{:,.3f}'.format(float(accuracy_score(test, pred)) * 100), \"%\")\n",
    "    print(\"     Precision: \", '{:,.3f}'.format(float(precision_score(test, pred, pos_label=label)) * 100), \"%\")\n",
    "    print(\"        Recall: \", '{:,.3f}'.format(float(recall_score(test, pred, pos_label=label)) * 100), \"%\")\n",
    "    print(\"      F1 score: \", '{:,.3f}'.format(float(f1_score(test, pred, pos_label=label)) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to load the data\n",
    "def load_data(path, file):\n",
    "    csv_path = os.path.join(path, file)\n",
    "    return pd.read_csv(csv_path, low_memory=False, encoding = \"ISO-8859-1\")\n",
    "\n",
    "# load data\n",
    "data = load_data(\"data\", \"spam.csv\")\n",
    "\n",
    "# let's take a look at the top 5 instances\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      "v1            5572 non-null object\n",
      "v2            5572 non-null object\n",
      "Unnamed: 2    50 non-null object\n",
      "Unnamed: 3    12 non-null object\n",
      "Unnamed: 4    6 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "Remove punctuation from each text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['v2'] = data['v2'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each text to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(input_str):\n",
    "    input_str = input_str.lower()\n",
    "    return input_str\n",
    "\n",
    "data['v2'] = data['v2'].apply(lambda x: lower_case(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  go until jurong point crazy available only in ...        NaN   \n",
       "1   ham                            ok lar joking wif u oni        NaN   \n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separete Features from Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.drop([\"v1\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "y = data[\"v1\"].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_arr = text.stack().tolist()\n",
    "text_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (y == 'spam')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1a92dc50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data['v1'].value_counts() )\n",
    "plt.legend(['Spam','Ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify using Tfid and Plain Text\n",
    "### Separete Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 4457\n",
      " X_test size: 1115 \n",
      "\n",
      "y_train size: 4457\n",
      " y_test size: 1115\n"
     ]
    }
   ],
   "source": [
    "# test set size of 20% of the data and the random seed 42 <3\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_arr, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train size:\", len(X_train))\n",
    "print(\" X_test size:\", len(X_test), \"\\n\")\n",
    "\n",
    "print(\"y_train size:\", len(y_train))\n",
    "print(\" y_test size:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 8344)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 8344)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.218 %\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier instance\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=4)\n",
    "\n",
    "# cross validation on the training set \n",
    "forest_scores = cross_val_score(forest_clf, X_train_vec, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print out the mean of the cross validation scores\n",
    "print(\"Accuracy: \", '{:,.3f}'.format(float(forest_scores.mean()) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  100.000 %\n",
      "   Recall:  100.000 %\n"
     ]
    }
   ],
   "source": [
    "# cross validate predict on the training set\n",
    "forest_train_pred = cross_val_predict(forest_clf, X_train_vec, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print precision and recall scores\n",
    "print(\"Precision: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")\n",
    "print(\"   Recall: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report (Test Set) :\n",
      "\n",
      "Accuracy Score:  97.130 %\n",
      "     Precision:  100.000 %\n",
      "        Recall:  78.667 %\n",
      "      F1 score:  88.060 %\n"
     ]
    }
   ],
   "source": [
    "# first train the model\n",
    "forest_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "forest_pred = forest_clf.predict(X_test_vec)\n",
    "\n",
    "# print out the classification report\n",
    "classification_report(\"Random Forest Classifier Report (Test Set)\", y_test, forest_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Using N-Grams\n",
    "### Generate 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for ii in range(0,len(text)):\n",
    "    words.append(str(text.iloc[ii]['v2']).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'only',\n",
       " 'in',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_all = []\n",
    "\n",
    "for word in words:\n",
    "    # get n-grams for the instance\n",
    "    n_gram = []\n",
    "    for i in range(len(word)-2+1):\n",
    "        n_gram.append(\"\".join(word[i:i+2]))\n",
    "    n_gram_all.append(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gountil',\n",
       " 'untiljurong',\n",
       " 'jurongpoint',\n",
       " 'pointcrazy',\n",
       " 'crazyavailable',\n",
       " 'availableonly',\n",
       " 'onlyin',\n",
       " 'inbugis',\n",
       " 'bugisn',\n",
       " 'ngreat',\n",
       " 'greatworld',\n",
       " 'worldla',\n",
       " 'lae',\n",
       " 'ebuffet',\n",
       " 'buffetcine',\n",
       " 'cinethere',\n",
       " 'theregot',\n",
       " 'gotamore',\n",
       " 'amorewat']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separete Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 4457\n",
      " X_test size: 1115 \n",
      "\n",
      "y_train size: 4457\n",
      " y_test size: 1115\n"
     ]
    }
   ],
   "source": [
    "# test set size of 20% of the data and the random seed 42 <3\n",
    "X_train, X_test, y_train, y_test = train_test_split(n_gram_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train size:\", len(X_train))\n",
    "print(\" X_test size:\", len(X_test), \"\\n\")\n",
    "\n",
    "print(\"y_train size:\", len(y_train))\n",
    "print(\" y_test size:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize 2-Grams Using Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvec = HashingVectorizer(lowercase=False, analyzer=lambda l:l, n_features=2**13, stop_words='.')\n",
    "\n",
    "# fit transform into the hash vector\n",
    "X_train = hvec.fit_transform(X_train)\n",
    "X_test = hvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 8192)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 8192)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Using 2-Grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  95.288 %\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier instance\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=4)\n",
    "\n",
    "# cross validation on the training set \n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print out the mean of the cross validation scores\n",
    "print(\"Accuracy: \", '{:,.3f}'.format(float(forest_scores.mean()) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  98.254 %\n",
      "   Recall:  98.254 %\n"
     ]
    }
   ],
   "source": [
    "# cross validate predict on the training set\n",
    "forest_train_pred = cross_val_predict(forest_clf, X_train, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print precision and recall scores\n",
    "print(\"Precision: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")\n",
    "print(\"   Recall: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report (Test Set) :\n",
      "\n",
      "Accuracy Score:  95.874 %\n",
      "     Precision:  99.057 %\n",
      "        Recall:  70.000 %\n",
      "      F1 score:  82.031 %\n"
     ]
    }
   ],
   "source": [
    "# first train the model\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "forest_pred = forest_clf.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "classification_report(\"Random Forest Classifier Report (Test Set)\", y_test, forest_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Using Burrows Wheeler Transform Distance (BWTD)\n",
    "### Separete Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 4457\n",
      " X_test size: 1115 \n",
      "\n",
      "y_train size: 4457\n",
      " y_test size: 1115\n"
     ]
    }
   ],
   "source": [
    "# test set size of 20% of the data and the random seed 42 <3\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_arr, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train size:\", len(X_train))\n",
    "print(\" X_test size:\", len(X_test), \"\\n\")\n",
    "\n",
    "print(\"y_train size:\", len(y_train))\n",
    "print(\" y_test size:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = vectorize(X_train)\n",
    "X_test_vec = vectorize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 65536)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 65536)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Using BWTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  96.545 %\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier instance\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=4)\n",
    "\n",
    "# cross validation on the training set \n",
    "forest_scores = cross_val_score(forest_clf, X_train_vec, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print out the mean of the cross validation scores\n",
    "print(\"Accuracy: \", '{:,.3f}'.format(float(forest_scores.mean()) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  99.332 %\n",
      "   Recall:  99.332 %\n"
     ]
    }
   ],
   "source": [
    "# cross validate predict on the training set\n",
    "forest_train_pred = cross_val_predict(forest_clf, X_train_vec, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print precision and recall scores\n",
    "print(\"Precision: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")\n",
    "print(\"   Recall: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report (Test Set) :\n",
      "\n",
      "Accuracy Score:  96.771 %\n",
      "     Precision:  100.000 %\n",
      "        Recall:  76.000 %\n",
      "      F1 score:  86.364 %\n"
     ]
    }
   ],
   "source": [
    "# first train the model\n",
    "forest_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "forest_pred = forest_clf.predict(X_test_vec)\n",
    "\n",
    "# print out the classification report\n",
    "classification_report(\"Random Forest Classifier Report (Test Set)\", y_test, forest_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Using BWTD With 2-Grams:\n",
    "### Separete Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_all = [\" \".join(x) for x in n_gram_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gountil untiljurong jurongpoint pointcrazy crazyavailable availableonly onlyin inbugis bugisn ngreat greatworld worldla lae ebuffet buffetcine cinethere theregot gotamore amorewat'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 4457\n",
      " X_test size: 1115 \n",
      "\n",
      "y_train size: 4457\n",
      " y_test size: 1115\n"
     ]
    }
   ],
   "source": [
    "# test set size of 20% of the data and the random seed 42 <3\n",
    "X_train, X_test, y_train, y_test = train_test_split(n_gram_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train size:\", len(X_train))\n",
    "print(\" X_test size:\", len(X_test), \"\\n\")\n",
    "\n",
    "print(\"y_train size:\", len(y_train))\n",
    "print(\" y_test size:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = vectorize(X_train)\n",
    "X_test_vec = vectorize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Using BWTD and 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.016 %\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier instance\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=4)\n",
    "\n",
    "# cross validation on the training set \n",
    "forest_scores = cross_val_score(forest_clf, X_train_vec, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print out the mean of the cross validation scores\n",
    "print(\"Accuracy: \", '{:,.3f}'.format(float(forest_scores.mean()) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  99.573 %\n",
      "   Recall:  99.573 %\n"
     ]
    }
   ],
   "source": [
    "# cross validate predict on the training set\n",
    "forest_train_pred = cross_val_predict(forest_clf, X_train_vec, y_train, cv=5, n_jobs=4)\n",
    "\n",
    "# print precision and recall scores\n",
    "print(\"Precision: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")\n",
    "print(\"   Recall: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred)) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report (Test Set) :\n",
      "\n",
      "Accuracy Score:  97.848 %\n",
      "     Precision:  99.219 %\n",
      "        Recall:  84.667 %\n",
      "      F1 score:  91.367 %\n"
     ]
    }
   ],
   "source": [
    "# first train the model\n",
    "forest_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "forest_pred = forest_clf.predict(X_test_vec)\n",
    "\n",
    "# print out the classification report\n",
    "classification_report(\"Random Forest Classifier Report (Test Set)\", y_test, forest_pred, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
